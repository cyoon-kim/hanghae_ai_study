> #### ğŸ“Œ ê³¼ì œ ìš”êµ¬ ì‚¬í•­
> - [x] AG_News dataset ì¤€ë¹„
> 	- Huggingface datasetì˜ `fancyzhx/ag_news`ë¥¼ load
> 	- `collate_fn` í•¨ìˆ˜ì— ë‹¤ìŒ ìˆ˜ì •ì‚¬í•­ë“¤ì„ ë°˜ì˜
>    - Truncationê³¼ ê´€ë ¨ëœ ë¶€ë¶„ë“¤ì„ ì‚­ì œ
> - [x] Classifier output, loss function, accuracy function ë³€ê²½
> 	- ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜ ë¬¸ì œëŠ” binary classificationì´ ì•„ë‹Œ ì¼ë°˜ì ì¸ classification ë¬¸ì œì…ë‹ˆë‹¤. MNIST ê³¼ì œì—ì„œ í–ˆë˜ ê²ƒ ì²˜ëŸ¼ `nn.CrossEntropyLoss` ë¥¼ ì¶”ê°€í•˜ê³  `TextClassifier`ì˜ ì¶œë ¥ ì°¨ì›ì„ ì˜ ì¡°ì •í•˜ì—¬ taskë¥¼ í’€ ìˆ˜ ìˆë„ë¡ ìˆ˜ì •
> 	- ê·¸ë¦¬ê³  ì •í™•ë„ë¥¼ ì¬ëŠ” `accuracy` í•¨ìˆ˜ë„ classificationì— ë§ì¶° ìˆ˜ì •
> - [x]  í•™ìŠµ ê²°ê³¼ report
>     - DistilBERT ì‹¤ìŠµê³¼ ê°™ì´ ë§¤ epoch ë§ˆë‹¤ì˜ train lossë¥¼ ì¶œë ¥í•˜ê³  ìµœì¢… ëª¨ë¸ì˜ test accuracyë¥¼ report ì²¨ë¶€


# [3ì£¼ì°¨] ê¸°ë³¸ê³¼ì œ - DistilBERTë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜

ë³¸ ê³¼ì œëŠ” pre-trainedëœ DistilBERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ AG_News ë°ì´í„°ì…‹ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•˜ê³  ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ì§„í–‰í•œ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“Œ ê³¼ì œ ëª©í‘œ
- Pre-trained DistilBERTë¥¼ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜ ë¬¸ì œì— ì ìš©
- Tokenizer ë¡œë”© ë° ë°ì´í„° ì „ì²˜ë¦¬
- ëª¨ë¸ fine-tuning ë° í‰ê°€


## ğŸ—ƒï¸ ë°ì´í„°ì…‹

### AG_News Dataset
ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.

#### ë°ì´í„° êµ¬ì„± (BaseëŠ” 5%ë§Œ ì‚¬ìš©)
| êµ¬ë¶„   | ë°ì´í„° ê°œìˆ˜ |
|--------|------------|
| train  | 6000       |
| test   | 380        |

#### í´ë˜ìŠ¤ êµ¬ì„±
| Index | Category  |
|-------|-----------|
| 0     | World     |
| 1     | Sports    |
| 2     | Business  |
| 3     | Sci/Tech  |

ë°ì´í„° ì˜ˆì‹œ:
```json
{
  "text": "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\band of ultra-cynics, are seeing green again.",
  "label": 2
}
```

## ğŸ› ï¸ Tokenizer ë° ë°ì´í„° ì „ì²˜ë¦¬
- DistilBERT tokenizer ì‚¬ìš©
- Tokenization ë° padding ì‘ì—… ìˆ˜í–‰ (ìë™ padding ì ìš©)
- ë°°ì¹˜ í¬ê¸°(batch size)ëŠ” 64ë¡œ ì„¤ì •

## ğŸ”§ ëª¨ë¸ êµ¬ì¡°
- Pre-trained DistilBERT ëª¨ë¸ ì‚¬ìš© (`distilbert-base-uncased`)
- ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶”ê°€ì ì¸ ì„ í˜• ë ˆì´ì–´(nn.Linear)ë¥¼ ì¶”ê°€í•˜ì—¬ í´ë˜ìŠ¤(4ê°œ)ë¥¼ ë¶„ë¥˜
- DistilBERTì˜ encoder íŒŒë¼ë¯¸í„°ëŠ” ë™ê²° (freeze)í•˜ì—¬ í•™ìŠµì—ì„œ ì œì™¸í•¨

## ğŸ“ˆ í•™ìŠµ ë° í‰ê°€
Accuracy over epoch
![image](https://github.com/user-attachments/assets/0b64e412-0491-4e04-a80a-735c49d7afda)

Loss over epoch
![image](https://github.com/user-attachments/assets/d75316da-6303-42f8-9ae8-484e1219f869)

- Optimizer: Adam
- Learning rate: 0.001
- Batch size: 64
- Epoch: 5
- í‰ê°€ ì§€í‘œ: ì •í™•ë„(accuracy)

## ğŸ“Š ì¶”ê°€ ì‹¤í—˜ ë° ê²°ê³¼ ë¶„ì„
ë…¸íŠ¸ë¶ì—ì„œ ì§„í–‰ëœ ì¶”ê°€ ì‹¤í—˜ê³¼ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

### ğŸ§ª ì‹¤í—˜ 1: clean text, weight decay ì„¤ì •
- ì†Œë¬¸ì íŠ¹ìˆ˜ë¬¸ì ì—¬ëŸ¬ ê³µë°± ë“± data ì „ì²˜ë¦¬
```python
def clean_text(text):
    text = text.lower()  # ì†Œë¬¸ì í†µì¼
    text = re.sub(r'\s+', ' ', text)  # ì—¬ëŸ¬ ê³µë°± â†’ í•˜ë‚˜
    text = re.sub(r'[^]*\]', '', text)  # ê´„í˜¸ ë‚´ìš© ì œê±°
    text = re.sub(r'https?://\S+|www\.\S+', '', text)  # URL ì œê±°
    text = re.sub(r'[^a-z0-9.,!?\'\" ]+', '', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'\s+', ' ', text)
    return text.strip()
```
- weight decay ì„¤ì •

#### ì‹¤í—˜ 1 ê²°ê³¼
![image](https://github.com/user-attachments/assets/e3b938f5-9c9d-4d90-b6cf-d5db3fe815e6)
test data ê¸°ì¤€ ì„±ëŠ¥ì´ ë” ì˜¬ë¼ê°€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

### ğŸ§ª ì‹¤í—˜ 2: business augmentation
![image](https://github.com/user-attachments/assets/3735118f-a1b8-4009-b7a2-7b67c7f05081)
label ë‹¹ accë¥¼ ì¸¡ì •í•˜ë©´ business labelì— ëŒ€í•œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
full_ds = load_dataset("fancyzhx/ag_news", split="train")
business_all = full_ds.filter(lambda x:x['label']==2)

n = len(business_all)

start = int(0.95 * n)
extra_business = business_all.select(range(start, n))

print(f"extra business data count is {len(extra_business)}")

augmented_train = concatenate_datasets([all_train_ds, extra_business]).shuffle(seed=42)
```
ë”°ë¼ì„œ businessë¥¼ labelë¡œ ê°€ì§„ 30000ê°œì˜ ë°ì´í„° ì¤‘ 5%ì¸ 1500ê°œë¥¼ train_dsì— ë”í•´ì£¼ì–´ business ë¥¼ ì¡°ê¸ˆ ë” í•™ìŠµí•˜ë„ë¡ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

#### ì‹¤í—˜ 2 ê²°ê³¼

|Class|	Before|	After|	ë³€í™”ëŸ‰ (Î”)|
|--|--|--|--|
|Business|	0.7571|	0.8571	|+0.1000 âœ…|
|Sci/Tech|	0.8600|	0.7800|	âˆ’0.0800 âŒ|
|Sports|	0.9381	|0.9381|	+0.0000 ğŸŸ°|
|World	|0.8247	|0.8351|	+0.0103 â¬†ï¸|

- Business ê°œì„  business ë°ì´í„° ì¶”ê°€ëŠ” ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤Œ
- Sci/Tech ì„±ëŠ¥ í•˜ë½ sci/techì™€ businessë¥¼ í—·ê°ˆë ¤í•˜ëŠ” ê²½í–¥ì´ ë³´ì„
- World ì•½ê°„ ìƒìŠ¹ Sport ê·¸ëŒ€ë¡œ business ë°ì´í„°ë¥¼ ì¶”ê°€í•œê±´ ë‘ labelì—ëŠ” ê±°ì˜ ì˜í–¥ ì—†ìŒ
- ê²°ë¡ ì ìœ¼ë¡œ businessì™€ sci/Techë¥¼ ëª¨ë¸ì´ í—·ê°ˆë ¤ í•œë‹¤ëŠ” ë¶„ì„ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤.

![image](https://github.com/user-attachments/assets/8c4918ad-e949-4986-927f-ec0977731e01)
- ì‹¤ì œ labelê°’ì— ë”°ë¼ ì–´ë–¤ predê°€ ì„ íƒë˜ì—ˆëŠ”ì§€ ì°ì–´ë´ë„ ë‘˜ì„ í—·ê°ˆë ¤í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
